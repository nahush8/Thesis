\relax 
\citation{mahadevan1992automatic}
\citation{mahadevan1992automatic}
\citation{smart2002effective}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{1}}
\citation{liu2014review}
\citation{ozaslaninspection}
\citation{das2015devices}
\citation{kober2012reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation and applications to general scenarios}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Quadrotor navigating through a confined space without GPS signal}}{2}}
\newlabel{fig:motivation}{{1.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Challenges}{2}}
\citation{chowdhary2014off}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contributions}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Organization of the Thesis}{4}}
\citation{littman1996algorithms}
\citation{wiering2012reinforcement}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{background}{{2}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Sequential Decision Making}{5}}
\newlabel{sequential_decision_making}{{2.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Approaches to solve sequential decision making}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Why Learning?}{6}}
\newlabel{whyLearning}{{2.1.2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Online Vs Off-line Learning}{6}}
\citation{puterman2014markov}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Rewards, and how to assign them ?}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Markov Decision Processes}{7}}
\newlabel{mdp}{{2.2}{7}}
\newlabel{mdp_def}{{1}{7}}
\newlabel{transition_function}{{2.2}{7}}
\citation{Bellman:1957}
\newlabel{reward_function}{{2.2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Policies}{8}}
\newlabel{policies}{{2.2.1}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Value Function and Bellman Equation}{8}}
\newlabel{value_function_equation}{{2.1}{8}}
\newlabel{value_function_state_action_equation}{{2.2}{8}}
\newlabel{bellman_equation}{{2.3}{8}}
\newlabel{bellman_optimality_equation}{{2.4}{9}}
\newlabel{bellman_optimality_equation}{{2.5}{9}}
\newlabel{v_q_relation}{{2.6}{9}}
\newlabel{v_q_relation}{{2.7}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Solving MDPs}{9}}
\newlabel{bellman}{{2.2.3}{9}}
\citation{kaelbling1996reinforcement}
\citation{berry1985bandit}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Reinforcement Learning (RL)}{10}}
\newlabel{rl}{{2.3}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Model of Reinforcement Learning}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A Simplified Reinforcement Learning Model}}{10}}
\newlabel{fig:rl_model}{{2.1}{10}}
\citation{kaelbling1996reinforcement}
\citation{strehl2006pac}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Exploration Vs. Exploitation}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Classification/Types}{11}}
\newlabel{types}{{2.3.3}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Model-free}{11}}
\citation{brafman2002r}
\citation{kearns2002near}
\@writefile{toc}{\contentsline {subsubsection}{Model-based}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Q-Learning}{12}}
\newlabel{q_learning_section}{{2.3.4}{12}}
\@writefile{toc}{\contentsline {subsubsection}{What is Q-Learning?}{12}}
\newlabel{q_function}{{2.8}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Q-Learning Algorithm}{13}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Q-Learning Algorithm}}{13}}
\newlabel{q_learning}{{1}{13}}
\@writefile{toc}{\contentsline {subsubsection}{The need of learning Q values.}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces An example gridlworld with stochastic actions}}{14}}
\newlabel{fig:gridworld_ex}{{2.2}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Learning Laser data and space complexity!}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Navigation with perception in the loop}}{14}}
\newlabel{fig:gp_laser}{{2.3}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Introduction to Gaussian Processes (GP)}{15}}
\newlabel{introToGPs}{{2.4}{15}}
\@writefile{toc}{\contentsline {subsubsection}{What are GPs ?}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Given ten noisy data points (error bars are indicated with vertical lines), we are interested in estimating the value of the eleventh point at $x^* = 1.2$.}}{15}}
\newlabel{fig:gp_intro}{{2.4}{15}}
\citation{rasmussen2003gaussian}
\@writefile{toc}{\contentsline {subsubsection}{Kernel Functions}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Gaussian Process Regression}{17}}
\newlabel{GPR}{{2.4.1}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces To find a function that is consistent over the observed data}}{17}}
\newlabel{fig:lease_square}{{2.5}{17}}
\citation{rasmussen2003gaussian}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces A Bivariate Normal Distribution}}{18}}
\newlabel{fig:bvnpdf}{{2.6}{18}}
\newlabel{equ:f_f*}{{2.13}{18}}
\citation{bou2010controller}
\citation{lupashin2010simple}
\citation{mahadevan1992automatic}
\citation{bagnell2001autonomous}
\citation{kormushev2010robot}
\citation{Shaker:2010:VLS:1901614.1902128}
\citation{sugimoto2016acquisition}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Gaussian Processes for Machine Learning}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Reinforcement Learning for UAVs}{19}}
\citation{gamedeep}
\citation{morton2016deep}
\citation{krizhevsky2012imagenet}
\citation{mnih2015human}
\citation{mnih2013playing}
\citation{mnih2013playing}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Deep Reinforcement Learning}{20}}
\newlabel{deep_rl_section}{{2.6}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces A naive representation of deep Q-network}}{21}}
\newlabel{fig:deep_q}{{2.7}{21}}
\citation{tokekar2014placement}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}The End to End GPQ Algorithm}{22}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{gpq}{{3}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Perception in the loop}{22}}
\citation{koenig2004design}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces A UAV equipped with a laser sensor}}{23}}
\newlabel{fig:perception_example}{{3.1}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Simulator setup}{23}}
\newlabel{sims}{{3.2}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A python based simulator for obstacle avoidance}}{23}}
\newlabel{fig:perception_sim_1}{{3.2}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A UAV equipped with laser sensor in Gazebo Robot Simulator}}{24}}
\newlabel{fig:perception_sim_2}{{3.3}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Laser data and $Q$-Learning}{24}}
\newlabel{laser_learning}{{3.2.1}{24}}
\citation{chowdhary2014off}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}End to end GPQ Algorithm}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Simulations and Results}{25}}
\newlabel{batch_gpq_algorithm}{{2}{26}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Batch GPQ Algorithm}}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Simulator Environment}}{27}}
\newlabel{fig:gpq_sim}{{3.4}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Reward as a function of time}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Reward obtained over time}}{28}}
\newlabel{fig:gpq_vs_q_reward}{{3.5}{28}}
\citation{cutler2014reinforcement}
\citation{taylor2007transfer}
\citation{li2011knows}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}The GP-MFRL Algorithm}{29}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{gpMfrl}{{4}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Multi-Fidelity Reinforcement Learning}{29}}
\citation{Dames2015}
\citation{rasmussen2003gaussian}
\citation{deisenroth2010efficient}
\citation{engel2005reinforcement}
\citation{puterman2014markov}
\citation{brafman2002r,kearns2002near}
\citation{sutton1998reinforcement}
\citation{strehl2006pac}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces MFRL framework: First simulator captures only gridworld movements of a point robot while second simulator has more fidelity using a physics simulator. Control can switch back and forth between simulators and real environment which is essentially the third simulator in the multi-fidelity simulator chain.}}{30}}
\newlabel{fig:mfrl_architecture}{{4.1}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Learning Transition Dynamics as a GP}{30}}
\citation{rasmussen2003gaussian}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Overview of the GP-MFRL algorithm }}{31}}
\newlabel{fig:gp_mfrl_system}{{4.2}{31}}
\newlabel{gaussian_mean}{{4.1}{31}}
\newlabel{gaussian_variance}{{4.2}{31}}
\citation{abbeel2006using,taylor2007transfer}
\citation{cutler2014reinforcement}
\citation{sutton1998reinforcement}
\newlabel{kernel_def}{{4.3}{32}}
\newlabel{velocity_def}{{4.4}{32}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}GP-MFRL Algorithm}{32}}
\citation{koenig2004design}
\citation{quigley2009ros}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Simulation Results}{34}}
\newlabel{gp-mfrl-sim}{{4.4}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The environment setup for a multi-fidelity simulator chain. The simple gridworld environment has two wall obstacles whereas the gazebo environment has four wall obstacles as shown.}}{34}}
\newlabel{fig:gp_mfrl_setup}{{4.3}{34}}
\newlabel{lt}{{4}{35}}
\newlabel{forins}{{8}{35}}
\newlabel{forins1}{{17}{35}}
\newlabel{forins2}{{20}{35}}
\newlabel{forins3}{{22}{35}}
\newlabel{forins4}{{30}{35}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces GP-MFRL Algorithm}}{35}}
\newlabel{GP-MFRL}{{3}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces  The figure represents the samples collected in each level of simulator for a $21 \times 21$ grid in a simple grid-world and Gazebo environments. $\Psi $ and $\psi $ were kept 0.4 and $0.1$}}{36}}
\newlabel{fig:epoch_samples}{{4.4}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Variance plot for $21 \times 21$ multi-fidelity environment after transition dynamics initialization and after algorithm has converged}}{36}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {After Initial Training}}}{36}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {After Convergence}}}{36}}
\newlabel{fig:heatmap1}{{4.5}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Representative simulations}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Variance plot for $21 \times 21$ multi-fidelity environment after transition dynamics initialization and after algorithm has converged}}{37}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {After Initial Training}}}{37}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {After Convergence}}}{37}}
\newlabel{fig:heatmap2}{{4.6}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Variance plot for $21 \times 21$ multi-fidelity environment after the algorithm has converged. Walls A and B are only present in the grid-world simulator, whereas all four walls are present in the Gazebo simulator.}}{37}}
\newlabel{fig:heatmap_four_walls_complex}{{4.7}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Effect of fidelity on the number of samples.}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces As we make first simulator more inaccurate by adding noise, the agent tends to gather more samples in second simulator }}{38}}
\newlabel{fig:gp_mfrl_samples}{{4.8}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Ratio of samples gathered in the second simulator to the total samples gathered increases with inaccuracy in the first simulator. The reference line depicts the average number of samples gathered over $10$ runs when only Gazebo simulator was present.}}{38}}
\newlabel{fig:gp_mfrl_ratio}{{4.9}{38}}
\citation{cutler2014reinforcement}
\citation{cutler2014reinforcement}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Effect of the confidence parameters.}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Ratio of samples gathered in second simulator vs. total samples gathered as we change the threshold or confidence parameters of the two simulators.}}{39}}
\newlabel{fig:threshold}{{4.10}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Comparison with R-max MFRL}{39}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Conclusion}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces  Discounted return in the start state Vs. the number of samples collected in the highest fidelity simulator.}}{40}}
\newlabel{fig:value_function}{{4.11}{40}}
\citation{morgenthal2014quality}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Bridge Inspection}{41}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{bridge_chapter}{{5}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Background}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Conventional Inspection of Bridges}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Conventional inspection units for Bridge Inspection: (left,Bridge Inspection platform with a truck crane) , A-30 Hi-Rail Under Bridge Units(right,N.E. Bridge Contractors Inc.)}}{42}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Truck Crane}}}{42}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Under Bridge Inspection unit}}}{42}}
\newlabel{fig:bridge_inspection}{{5.1}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Bridgeriggers' Aspen A-75 under-bridge inspection crane overturns on Sakonnet River Bridge in Rhode Island; August 30, 2016}}{42}}
\newlabel{fig:bridge_fail}{{5.2}{42}}
\citation{dji_frame}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}UAVs in Bridge Inspection}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Present Work}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}The System Setup}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces UAV used for the experiments}}{44}}
\newlabel{fig:dji_frame}{{5.3}{44}}
\citation{flea_camera}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces System Components}}{45}}
\newlabel{fig:system_components}{{5.4}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Flea3 2.0 MP Color USB3 Vision (e2v EV76C5706F)}}{45}}
\newlabel{fig:cam}{{5.5}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Intel NUC NUC5I7RYH}}{46}}
\newlabel{fig:nuc}{{5.6}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Pixhawk Flight Controller}}{46}}
\newlabel{fig:pixhawk}{{5.7}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces LIDAR-Lite v$3$}}{47}}
\newlabel{fig:lidar}{{5.8}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Ublox Neo-M$8$N GPS}}{48}}
\newlabel{fig:gps}{{5.9}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces E800 Tuned Propulsion System by DJI}}{48}}
\newlabel{fig:dji_propulsion_system}{{5.10}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Camera Software and ROS nodes}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Camera view and ROS-bag record}}{49}}
\newlabel{fig:cam_rqt}{{5.11}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Flights without GPS signal}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Indoor flight of the UAV visually inspecting the structure}}{49}}
\newlabel{fig:indoor_flight}{{5.12}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Outdoor Inspection}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Outdoor flight of the UAV visually inspecting the structure}}{50}}
\newlabel{fig:outdoor_flight}{{5.13}{50}}
\bibdata{refs}
\bibstyle{plain}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}conclusion and Future research}{51}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
